{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHH eval with and without CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hhh_dataset = load_dataset(\"HuggingFaceH4/hhh_alignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_boolq_string = '''\n",
    "task: demo_boolq\n",
    "dataset_path: super_glue\n",
    "dataset_name: boolq\n",
    "output_type: multiple_choice\n",
    "training_split: train\n",
    "validation_split: validation\n",
    "doc_to_text: \"{{passage}}\\nQuestion: {{question}}?\\nAnswer:\"\n",
    "doc_to_target: label\n",
    "doc_to_choice: [\"no\", \"yes\"]\n",
    "should_decontaminate: true\n",
    "doc_to_decontamination_query: passage\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "'''\n",
    "with open('boolq.yaml', 'w') as f:\n",
    "    f.write(YAML_boolq_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-2.8b \\\n",
    "    --include_path ./ \\\n",
    "    --tasks demo_boolq \\\n",
    "    --limit 10"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
