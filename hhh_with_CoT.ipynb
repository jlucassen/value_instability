{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHH eval with and without CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/joshua_clymer/miniconda3/envs/redteam2/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-04-03:04:00:45,429 INFO     [utils.py:148] Note: NumExpr detected 20 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-04-03:04:00:45,430 INFO     [utils.py:161] NumExpr defaulting to 8 threads.\n",
      "/data/joshua_clymer/miniconda3/envs/redteam2/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/joshua_clymer/miniconda3/envs/redteam2/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9334039ff4647cc801c2f1a40de9621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/joshua_clymer/miniconda3/envs/redteam2/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/joshua_clymer/miniconda3/envs/redteam2/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "from lm_eval import api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_test_hhh_string = '''\n",
    "task: test_hhh\n",
    "dataset_path: HuggingFaceH4/hhh_alignment\n",
    "dataset_name: harmless\n",
    "output_type: multiple_choice\n",
    "training_split: null\n",
    "validation_split: null\n",
    "doc_to_text: input\n",
    "doc_to_target: 0\n",
    "doc_to_choice: targets[\"choices\"]\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "'''\n",
    "with open('test_hhh.yaml', 'w') as f:\n",
    "    f.write(YAML_test_hhh_string)\n",
    "\n",
    "# YAML_boolq_string = '''\n",
    "# task: demo_boolq\n",
    "# dataset_path: super_glue\n",
    "# dataset_name: boolq\n",
    "# output_type: multiple_choice\n",
    "# training_split: train\n",
    "# validation_split: validation\n",
    "# doc_to_text: \"{{passage}}\\nQuestion: {{question}}?\\nAnswer:\"\n",
    "# doc_to_target: label\n",
    "# doc_to_choice: [\"no\", \"yes\"]\n",
    "# should_decontaminate: true\n",
    "# doc_to_decontamination_query: passage\n",
    "# metric_list:\n",
    "#   - metric: acc\n",
    "# '''\n",
    "# with open('boolq.yaml', 'w') as f:\n",
    "#     f.write(YAML_boolq_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/joshua_clymer/miniconda3/bin/lm_eval\", line 5, in <module>\n",
      "    from lm_eval.__main__ import cli_evaluate\n",
      "ModuleNotFoundError: No module named 'lm_eval'\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Terminal command to run:\n",
    "lm_eval --model hf --model_args pretrained=meta-llama/Llama-2-7b-chat-hf --include_path ./ --tasks test_hhh --limit 10\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "display-redteam2",
   "language": "python",
   "name": "redteam2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
