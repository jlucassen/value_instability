{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_eval import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_test_hhh_string = '''\n",
    "task: test_hhh\n",
    "dataset_path: HuggingFaceH4/hhh_alignment\n",
    "dataset_name: harmless\n",
    "output_type: multiple_choice\n",
    "test_split: test\n",
    "doc_to_text: input\n",
    "doc_to_target: 0\n",
    "doc_to_choice: {{targets[\"choices\"]}}\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "'''\n",
    "with open('test_hhh.yaml', 'w') as f:\n",
    "    f.write(YAML_test_hhh_string)\n",
    "\n",
    "# YAML_boolq_string = '''\n",
    "# task: demo_boolq\n",
    "# dataset_path: super_glue\n",
    "# dataset_name: boolq\n",
    "# output_type: multiple_choice\n",
    "# training_split: train\n",
    "# validation_split: validation\n",
    "# doc_to_text: \"{{passage}}\\nQuestion: {{question}}?\\nAnswer:\"\n",
    "# doc_to_target: label\n",
    "# doc_to_choice: [\"no\", \"yes\"]\n",
    "# should_decontaminate: true\n",
    "# doc_to_decontamination_query: passage\n",
    "# metric_list:\n",
    "#   - metric: acc\n",
    "# '''\n",
    "# with open('boolq.yaml', 'w') as f:\n",
    "#     f.write(YAML_boolq_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Terminal commands that don't work:\n",
    "lm_eval --model hf --model_args pretrained=meta-llama/Llama-2-7b-chat-hf --tasks ./test_hhh.yaml --limit 10\n",
    "lm_eval --model hf --model_args pretrained=meta-llama/Llama-2-7b-chat-hf --tasks ./test_hhh --limit 10\n",
    "lm_eval --model hf --model_args pretrained=meta-llama/Llama-2-7b-chat-hf --tasks /test_hhh --limit 10\n",
    "\n",
    "lm_eval --model hf --model_args pretrained=meta-llama/Llama-2-7b-chat-hf --include_path ./test_hhh_config --tasks test_hhh --limit 10\n",
    "\n",
    "With accelerate:\n",
    "accelerate launch -m lm_eval --model hf --model_args pretrained=meta-llama/Llama-2-7b-chat-hf --include_path ./ --tasks test_hhh --limit 10\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
